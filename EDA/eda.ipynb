{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis Aims\n",
    "**Exploring relationships of variables with the response variable**\n",
    "\n",
    " This stage is all about understanding the data and its relationship with the response variable.\n",
    " The goals are to clean the data, identify patterns, and establish a foundation for modelling.\n",
    "\n",
    " 1. **Data cleaning & structure of the data:**\n",
    "    - Check for missing values and decide on how to handle missing values if any\n",
    "    - Detect duplicates\n",
    "    - Correct data inconsistencies: Ensure categorical variables have consistent labels and numerical data is in correct range.\n",
    "\n",
    " 2. **Feature Engineering**\n",
    "    - Attempt to create additional feautures that could improve the model and explain hidden relationships in the data\n",
    "\n",
    " 3. **Distributions of Numerical Variables**\n",
    "    - Look at skewness for possible outliers in the data\n",
    "\n",
    " 4. **Apply feature Engineering again**\n",
    "    - After look at dist of numeric vars , may need to apply feature engineering again\n",
    "\n",
    " 4. **Explore the response variable:**\n",
    "    - Check class distribution of the target variable (e.g., imbalance in 0/1 classess)\n",
    "    \n",
    "\n",
    " 5. **Explore predictor variables:**\n",
    "    - Look at relationships between numeric predictors & response , and relationships between categorical predictors and response.\n",
    "    - Also includes statistical tests to look at evidence to suggest including variables in the statistical model.\n",
    "\n",
    " 6. **Explore Interactions with response variable**\n",
    "    - Attempt to find possible interaction effects to include in the statistical model\n",
    "    - Bivariate analysis can sometimes be misleading and so looking at more complex relationships can sometimes uncover hidden patterns in the data\n",
    "\n",
    " 7. **Identify relationships:**\n",
    "    - Correlation analysis for numerical predictors to detect linear relationships\n",
    "    - Explore possible multicollinearity\n",
    "\n",
    "**Notes on the variable meanings**\n",
    "- Payment delay: Total number of days for delay in payment over the entire subscription period up until data was collected\n",
    "- Usage freq : Average usage on a monthly basis\n",
    "- Tenure : Number of months using the service\n",
    "- Support calls: Number of support calls over the entire usage period up until data was collected\n",
    "- Last interaction: Number of days since last interaction with customer\n",
    "- Churn: 1 -> Yes customer cancelled the service . 0 -> Customer still using the service\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.) **Data cleaning & structure of the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "customer_churn_df=pd.read_csv('../data/customer_churn_training.csv')\n",
    "customer_churn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data types\n",
    "customer_churn_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the data\n",
    "customer_churn_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values\n",
    "customer_churn_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df[customer_churn_df.isnull().any(axis=1)]\n",
    "# basically an entire row of missing values and so we can drop this observation\n",
    "customer_churn_df=customer_churn_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for duplicate records by CustomerID\n",
    "boolean_series=customer_churn_df.duplicated(subset=['CustomerID'])\n",
    "duplicates=customer_churn_df[boolean_series]\n",
    "print(\"Number of duplicate rows by customerid: {}\".format(len(duplicates)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Churn variable into a Category\n",
    "\n",
    "customer_churn_df['Churn']=customer_churn_df['Churn'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure categorical variables have consistent labels\n",
    "categorical_columns=customer_churn_df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(type(categorical_columns))\n",
    "print(categorical_columns)\n",
    "\n",
    "for col in categorical_columns:\n",
    "    print()\n",
    "    print(\"Levels and counts for {}\".format(col))\n",
    "    print()\n",
    "    print(customer_churn_df[col].value_counts())\n",
    "\n",
    "# cat vars do seem to have consistent levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check ranges of all numerical vars\n",
    "numeric_columns=customer_churn_df.select_dtypes(include=['float64']).columns.tolist()\n",
    "numeric_columns.remove(\"CustomerID\")\n",
    "print(numeric_columns)\n",
    "\n",
    "for col in numeric_columns:\n",
    "    print()\n",
    "    print(\"Descriptive statistics for {}\".format(col))\n",
    "    print()\n",
    "    print(customer_churn_df[col].describe())\n",
    "\n",
    "# all the numerical vars seems to have acceptable ranges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.) **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df['Total Usage']=customer_churn_df['Tenure']*customer_churn_df['Usage Frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use K means algorithm to identify groupings in age \n",
    "# the groupings will have minimum variance within each group\n",
    "# after this we can assign labels to the groupings\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standardize the age data\n",
    "scaler = StandardScaler()\n",
    "customer_churn_df['age_scaled'] = scaler.fit_transform(customer_churn_df[['Age']])\n",
    "\n",
    "# Elbow method to find optimal k\n",
    "inertia = []\n",
    "k_range = range(1, 10)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(customer_churn_df[['age_scaled']])\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal number of clusters looks like it should be 3 \n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "customer_churn_df['cluster'] = kmeans.fit_predict(customer_churn_df[['age_scaled']])\n",
    "\n",
    "# Reverse the scaling to understand the group ranges\n",
    "customer_churn_df['age_group'] = kmeans.cluster_centers_[customer_churn_df['cluster']].flatten() * scaler.scale_[0] + scaler.mean_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in sorted(customer_churn_df['cluster'].unique()):\n",
    "    ages_in_cluster = customer_churn_df[customer_churn_df['cluster'] == cluster]['Age']\n",
    "    print(f\"Cluster {cluster}: {ages_in_cluster.min()} to {ages_in_cluster.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the above the groupings for age looks to be the following\n",
    "\n",
    "# Cluster 1: 18.0 to 35.0 -> Young Adult\n",
    "\n",
    "# Cluster 2: 36.0 to 50.0 -> Middle Aged Adult\n",
    "\n",
    "# Cluster 3: 51.0 to 65.0 -> Senior Adult\n",
    "\n",
    "# bin the Age variable into the following bins so that we can explore possible patterns within each age group\n",
    "def cat_age(age):\n",
    "    if age >=18 and age<=35:\n",
    "        return \"Young Adult\"\n",
    "    elif age >= 36 and age<=55:\n",
    "        return \"Middle Aged Adult\"\n",
    "    elif age>=56 and age<=65:\n",
    "        return \"Senior Adult\"\n",
    "\n",
    "customer_churn_df['Age Cat']=customer_churn_df['Age'].apply(cat_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.) **Distributions of Numeric Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Function to plot distributions with KDE\n",
    "def plot_kde_distributions(dataframe:pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Plots the KDE distribution of numeric columns in the dataframe to assess outliers.\n",
    "\n",
    "    :param dataframe: pd.DataFrame - Input DataFrame\n",
    "    :param columns: list or None - List of columns to plot. If None, plots all numeric columns.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Select only numeric columns\n",
    "    columns = dataframe.select_dtypes(include=\"number\").columns.tolist()\n",
    "    columns.remove(\"CustomerID\")\n",
    "    # Plot KDE for each numeric column\n",
    "    for column in columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.kdeplot(data=dataframe, x=column, fill=True, color=\"blue\", alpha=0.5)\n",
    "        plt.title(f\"KDE Plot of {column}\", fontsize=14)\n",
    "        plt.xlabel(column, fontsize=12)\n",
    "        plt.ylabel(\"Density\", fontsize=12)\n",
    "        plt.axvline(dataframe[column].mean(), color=\"red\", linestyle=\"--\", label=\"Mean\")\n",
    "        plt.axvline(dataframe[column].median(), color=\"green\", linestyle=\"--\", label=\"Median\")\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "# Plot distributions\n",
    "plot_kde_distributions(customer_churn_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extreme skewness either +ve or -ve suggest outliers\n",
    "\n",
    "def summary_measures(df:pd.DataFrame)->None:\n",
    "    numeric_columns=df.select_dtypes(include='number').columns.tolist()\n",
    "    numeric_columns.remove(\"CustomerID\")\n",
    "\n",
    "    for col in numeric_columns:\n",
    "        data=df[col]\n",
    "        print(\"Summary measures for {}\".format(col))\n",
    "        print(\"\\n\")\n",
    "        summary_measures=pd.DataFrame({\n",
    "            \"Mean\":data.mean(),\n",
    "            \"Median\":data.median(),\n",
    "            \"Mode\":data.mode(),\n",
    "            \"Std\":data.std(),\n",
    "            \"Count\":data.count(),\n",
    "            \"Min\":data.min(),\n",
    "            \"Max\":data.max(),\n",
    "            \"Skewness\":data.skew(),\n",
    "            \"Kurtosis\":data.kurt()\n",
    "        })\n",
    "        print(summary_measures)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "\n",
    "summary_measures(customer_churn_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpreting distributions of numeric variables**\n",
    "- Distributions for Age, Tenure ,Last Interaction,Usage Frequency, Total Spend and Payment Delay are close to symmetric based on the skewness value being between -0.5 and 0.5. This indicates we may have few outliers for these variables based on the data being less skewed and closer to be symmetric. This is just a guide and further investigation will still need to be done.\n",
    "- Total Usage seems to be positively skewed indicating possible outliers in the data\n",
    "- Expected Customer Value also seems to be extremly postively skewed , indicating many outliers in the data\n",
    "- Distribution for Support Calls has many peaks suggesting this variable should be converted to a Categorical Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the IQR method to define cut off values for the outlier classification for lower and upper bounds\n",
    "\n",
    "def iqr_method_outlier(df:pd.DataFrame,variable:str):\n",
    "    before=df.shape[0]\n",
    "    print(\"Size of orignal data {}\".format(before))\n",
    "    data_series=df[variable]\n",
    "    q1=data_series.quantile(0.25)\n",
    "    q3=data_series.quantile(0.75)\n",
    "    iqr=q3-q1\n",
    "    lower_bound=q1-1.5*iqr\n",
    "    upper_bound=q3+1.5*iqr\n",
    "    print(\"lower bound {}\".format(lower_bound))\n",
    "    print(\"upper bound {}\".format(upper_bound))\n",
    "    df=df[(df[variable]>=upper_bound) | (df[variable]<=lower_bound)]\n",
    "    after=df.shape[0]\n",
    "    print(\"Number of outliers {}\".format(after))\n",
    "    print(\"proportion of outliers {}\".format(round(after/before,2)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply Feature Engineering Again**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K means to find groupings for the number of Support Calls\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standardize the age data\n",
    "scaler = StandardScaler()\n",
    "customer_churn_df['support_calls_scaled'] = scaler.fit_transform(customer_churn_df[['Support Calls']])\n",
    "\n",
    "# Elbow method to find optimal k\n",
    "inertia = []\n",
    "k_range = range(1, 10)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(customer_churn_df[['age_scaled']])\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.plot(k_range, inertia, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "customer_churn_df['support_calls_cluster'] = kmeans.fit_predict(customer_churn_df[['support_calls_scaled']])\n",
    "\n",
    "# Reverse the scaling to understand the group ranges\n",
    "customer_churn_df['support_calls_group'] = kmeans.cluster_centers_[customer_churn_df['support_calls_cluster']].flatten() * scaler.scale_[0] + scaler.mean_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cluster in sorted(customer_churn_df['support_calls_cluster'].unique()):\n",
    "    ages_in_cluster = customer_churn_df[customer_churn_df['support_calls_cluster'] == cluster]['Support Calls']\n",
    "    print(f\"Cluster {cluster}: {ages_in_cluster.min()} to {ages_in_cluster.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based on the distribution of support calls having many peaks\n",
    "# suggests we should categorize the variable\n",
    "\n",
    "# Cluster 1: 0.0 to 2.0 -> Low Support \n",
    "# Cluster 2: 3.0 to 5.0 -> Medium Support\n",
    "# Cluster 3: 6.0 to 10.0 -> High Support\n",
    "\n",
    "def cat_support(support):\n",
    "    if support >=6 and support<=10:\n",
    "        return \"High\"\n",
    "    elif support >= 3 and support<=5:\n",
    "        return \"Medium\"\n",
    "    elif support>=0 and support<=2:\n",
    "        return \"Low\"\n",
    "\n",
    "customer_churn_df['Support Cat']=customer_churn_df['Support Calls'].apply(cat_support)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df['Support Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df['Age Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.) **Explore the response variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if the target variable is balanced or not\n",
    "customer_churn_df['Churn'].value_counts()\n",
    "# the data set is roughly balanced and does not require class imbalancing methods like smote ,random sampling etc ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object dtypes to category dtypes for effeciency\n",
    "customer_churn_df[customer_churn_df.select_dtypes(include=['object']).columns]=customer_churn_df.select_dtypes(include=['object']).astype('category')\n",
    "customer_churn_df['Churn']=customer_churn_df['Churn'].astype('category')\n",
    "customer_churn_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.) **Explore relationships between predictor variables and response variable**\n",
    "- numeric variables vs response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouped_box_plot(data: pd.DataFrame, variable: str):\n",
    "    \"\"\"\n",
    "    Creates a box plot for Cat var vs Churn using Plotly Express.\n",
    "\n",
    "    Parameters:\n",
    "        data (pd.DataFrame): The input DataFrame containing the data.\n",
    "        variable (str): The column name representing the variable of intrest.\n",
    "\n",
    "    Returns:\n",
    "        plotly.graph_objects.Figure: The generated box plot figure.\n",
    "    \"\"\"\n",
    "    fig = px.box(data, x='Churn', y=variable, color='Churn')\n",
    "    fig.update_layout(\n",
    "        title=\"Distribution of {} by Churn\".format(variable)\n",
    "                      )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total usage vs churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Total Usage')\n",
    "# does not seem to be much of a diff in total usage for customers who churn vs those who do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outliers=iqr_method_outlier(customer_churn_df,'Total Usage')\n",
    "print(outliers['Total Usage'].describe())\n",
    "# issue with the higher total usage values that we are observing is the following\n",
    "# the column Total Usage is computed using Usage Frequency* Tenure\n",
    "# Usage Frequency is a computed column in the data (Average usage in a month ) \n",
    "# as to if that average was computed using a median or normal mean which is not robust to outliers , one cannot say for sure\n",
    "# The higher the average usage frequency and tenure then the higher the total usage would be\n",
    "\n",
    "# The outliers should remain and not be tampered with because customers can have rather high total usage\n",
    "# it would of been nice if a total usage variable was recorded\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outliers['Churn'].value_counts())\n",
    "print(outliers['Tenure'].describe())\n",
    "print(outliers['Usage Frequency'].describe())\n",
    "\n",
    "# we can see that with the rather high usage that we have high tenure with min being 54 months and max being 60 months\n",
    "# we also have high usage frequency . min being 27 and max being 30\n",
    "\n",
    "# Median tenure for full data : 32\n",
    "# STD tenure for full data : 17 (quite a high variance) range (15,49)\n",
    "# Median usage frequency for full data : 16\n",
    "# STD usage frequency for full data : 8 \n",
    "\n",
    "# what we are seeing here is that customers with rather extremly high total usage relative to other data points\n",
    "# makes sense because of the min and max tenure and the min and max usage frequency\n",
    "\n",
    "# These customers have been the most loyal cusomers obviously because they are getting value from the product or service\n",
    "# as a result you would expect the Total usage for them to be higher on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Check for equal variance using Levene's test\n",
    "from scipy.stats import levene,ttest_ind\n",
    "\n",
    "def t_test_levene_variance(data:pd.DataFrame,variable:str)->None:\n",
    "    \"\"\"\n",
    "    Performs a t test and checks for equal variance between the distributions of the 2 groups.\n",
    "    Based on if we have equal variance or not , the appropriate t test will be used.\n",
    "\n",
    "    # No need to check for normality of the distributions within each group since our sample sizes are large enough.\n",
    "    # By the CLT if the sample sizes are large enough then the sampling dist will be normal\n",
    "\n",
    "    Parameters:\n",
    "    - variable: The column name in the dataset (e.g., 'Usage Frequency').\n",
    "    - data (DataFrame): A DataFrame containing customer churn data with a 'Churn' column.\n",
    "\n",
    "    \"\"\"\n",
    "    churned_total=customer_churn_df[customer_churn_df['Churn']==1][variable]\n",
    "    not_churned=customer_churn_df[customer_churn_df['Churn']==0][variable]\n",
    "\n",
    "    # Perform Levene's test\n",
    "    stat, p_value = levene(churned_total, not_churned)\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"Levene's test statistic: {stat}\")\n",
    "    print(f\"p-value: {p_value}\")\n",
    "\n",
    "    # Interpretation\n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis: Variances are significantly different->Implement Welch t-test\")\n",
    "        t_stat, p_value = ttest_ind(churned_total, not_churned, equal_var=False)\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: Variances are equal.\")\n",
    "        t_stat, p_value = ttest_ind(churned_total, not_churned, equal_var=True)\n",
    "        \n",
    "  \n",
    "    if p_value < 0.05:\n",
    "        print(\"Reject the null hypothesis: There is a statistically significant difference between means of {} for churned and not churned.\".format(variable))\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No significant difference between the group means.\")\n",
    "   \n",
    "\n",
    "t_test_levene_variance(data=customer_churn_df,variable=\"Total Usage\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above we applied the stastical test for difference in means on the full data\n",
    "# we will now remove the outliers and see what impact this has on the statistical test\n",
    "\n",
    "lower_bound=-717.0\n",
    "upper_bound=1611.0\n",
    "df=customer_churn_df\n",
    "no_outliers=df[(df['Total Usage']>=lower_bound) & (df['Total Usage']<=upper_bound)]\n",
    "print(no_outliers.shape)\n",
    "t_test_levene_variance(data=no_outliers,variable=\"Total Usage\") \n",
    "\n",
    "# we still end up with the same conclution that we have a statistically significant difference in means of total usage for \n",
    "# churned and not churned \n",
    "\n",
    "# This shows that our statistical test above with the outliers is sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age vs Churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Age')\n",
    "# the median age seems higher for customers who do cancel their subcription , though this difference does not seem to be that large\n",
    "# does not seem to be much difference in variability between the 2 groups\n",
    "# no outliers detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_levene_variance(data=customer_churn_df,variable=\"Age\")\n",
    "# Age seems to have an impact on churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenure vs Churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Tenure')\n",
    "# the median tenure seems to be higher for those who churn vs those who do not\n",
    "# lower variability in tenure for those who churn vs those who do not churn having higher variability\n",
    "# no outliers detected\n",
    "\n",
    "# longer tenure seems to be related with churn - proactive strategies to keep clients with long tenure may be needed to keep the customers\n",
    "# defining how long is a long tenure could be investigated.\n",
    "\n",
    "# collecting information on why customers churn may also be useful for improving the product or service\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply statistical test to see if we have statistically significant difference between groups for Tenure\n",
    "# Look at a statistical test to assess the differences between the 2 groups for Tenure\n",
    "t_test_levene_variance(data=customer_churn_df,variable=\"Tenure\") \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage Frequency vs Churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Usage Frequency')\n",
    "# slightly lower median usage frequency for those who churn vs those who do not,but not really much of a difference\n",
    "# we have more variability for those who churn in term of usage frequency as compared with those who do not churn.\n",
    "# this higher variability for those who churn in terms of usage frequency indicated that some of the customers who churn\n",
    "# have lower usage freqency and some have higher usage frequency\n",
    "\n",
    "\n",
    "# Investigation into why customers use the product/service less may be useful into retaining the customer or atleast improving the service/product\n",
    "# sometimes it could be that the product/service is complex for the end user and so proactively engaging with customers to increase usage frequency\n",
    "# can aid in longer rentention of the customer\n",
    "\n",
    "# no outliers detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_levene_variance(data=customer_churn_df,variable=\"Usage Frequency\") \n",
    "# based on this usage frequency seems to have impact on churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Calls vs Churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Support Calls')\n",
    "# The median number of support calls for those who churn is higher than for those who do no churn\n",
    "\n",
    "# non churned customers have more variability in number of support calls as compared with churned customers\n",
    "# this suggests that non churned customers are making very few calls and some are making much more calls.\n",
    "# this could point to difference in the nature of support required or issues faced by non churned customers\n",
    "\n",
    "# Understanding the the nature of support calls for both churned and not churned customers may be more impactful into understanding\n",
    "# why customers churn\n",
    "\n",
    "# no outliers detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_levene_variance(data=customer_churn_df,variable=\"Support Calls\") \n",
    "# based on this evidence to suggest support calls have an impact on churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Payment Delay vs Churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Payment Delay')\n",
    "# customers who churned seemed to have a higher payment delay (days) than those who did not churn\n",
    "# we have some outliers on the lower end for payment delay for those who churned , but these could be customers who\n",
    "# churned based on the nature of the support calls, product/service not user freindly or product/service not adding value to their\n",
    "# intended use case.\n",
    "\n",
    "# payment delay also could be attributed to a business having cash flow problems \n",
    "# perhaps revised payment plans could result in retained customers and greater value in the future ( play the long game)\n",
    "# it is not that the buisness sees no value but more that they could be struggling financially at a specific point in time\n",
    "# target approaches to understand why payment delays happen could be impactful especially for customers with high payment delay\n",
    "\n",
    "# also investigating if the product/service is to expensive is helpful in positioning the product/service to be competitive in the market\n",
    "# for reduction in payment delays and reduced customer churn\n",
    "\n",
    "\n",
    "# no outliers detected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_levene_variance(data=customer_churn_df,variable=\"Payment Delay\") \n",
    "# evidence to suggest payment delay should be used as a feature in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Spend vs Churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Total Spend')\n",
    "# Median total spend for customers who churn is lower than for customers who do not churn\n",
    "# though it is quite variable in both the cases where customers churn and do not churn\n",
    "\n",
    "# the variability could be due to affordability or needs\n",
    "\n",
    "# again pricing the product strategically to be competetive may be of value to see if total spend increases and thus reduction in churn\n",
    "\n",
    "# No outliers detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_levene_variance(data=customer_churn_df,variable=\"Total Spend\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Interaction vs Churn\n",
    "grouped_box_plot(data=customer_churn_df,variable='Last Interaction')\n",
    "# does not seem to be much of a difference between the distributions of last interaction for customers who churn vs do not churn\n",
    "# possibly indicating that last interaction is not a useful predictor for churn\n",
    "\n",
    "# no outliers detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_test_levene_variance(data=customer_churn_df,variable=\"Last Interaction\") \n",
    "# Evidence to suggest including Last Interaction in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Categorical variables vs response**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_proportions(variable:str, data:pd.DataFrame)->pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the proportions of churned and not churned customers for a given variable.\n",
    "\n",
    "    Parameters:\n",
    "    - variable: The column name in the dataset to group by (e.g., 'Gender').\n",
    "    - data (DataFrame): A DataFrame containing customer churn data with a 'Churn' column.\n",
    "\n",
    "    Returns:\n",
    "    - combined_data (DataFrame): A DataFrame showing proportions of churned and not churned customers for the given variable.\n",
    "    \"\"\"\n",
    "    # Separate churned and not churned customers\n",
    "    churned_customers = data[data['Churn'] == 1]\n",
    "    not_churned_customers = data[data['Churn'] == 0]\n",
    "\n",
    "    # Calculate totals\n",
    "    total_churned = len(churned_customers)\n",
    "    total_not_churned = len(not_churned_customers)\n",
    "\n",
    "    # Group by variable and calculate proportions for churned customers\n",
    "    churned_counts = churned_customers.groupby(variable).size()\n",
    "    churned_proportions = (churned_counts / total_churned) * 100\n",
    "    churned_df = churned_proportions.reset_index(name='proportion')\n",
    "    churned_df['Churn'] = 1\n",
    "\n",
    "    # Group by variable and calculate proportions for not churned customers\n",
    "    not_churned_counts = not_churned_customers.groupby(variable).size()\n",
    "    not_churned_proportions = (not_churned_counts / total_not_churned) * 100\n",
    "    not_churned_df = not_churned_proportions.reset_index(name='proportion')\n",
    "    not_churned_df['Churn'] = 0\n",
    "\n",
    "    # Combine the two DataFrames\n",
    "    combined_data = pd.concat([churned_df, not_churned_df], ignore_index=True)\n",
    "    combined_data['proportion'] = combined_data['proportion'].round(2)\n",
    "\n",
    "    return combined_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def chi_square_test(data:pd.DataFrame,variable:str)->None:\n",
    "    \"\"\"\n",
    "    Computes the chi sqaure test statistic,p-value and expected cell count table\n",
    "    and the performs the hypothesis test which tests for association between the 2 categorical variables.\n",
    "\n",
    "    Parameters:\n",
    "    - variable: The column name in the dataset which will be used in conjunction with the Churn variable\n",
    "    - data (DataFrame): A DataFrame containing customer churn data with a 'Churn' column.\n",
    "\n",
    "    \"\"\"\n",
    "    contingency_table = pd.crosstab(data[variable], data['Churn'])\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "    print(\"Chi-Square Statistic:\", chi2)\n",
    "    print(\"p-value:\", p)\n",
    "    print(\"Degrees of Freedom:\", dof)\n",
    "    print(\"Expected Frequencies:\\n\", expected)\n",
    "\n",
    "    # Interpretation\n",
    "    alpha = 0.05  # Significance level -> type 1 error \n",
    "    if p < alpha:\n",
    "        print(\"Reject the null hypothesis: There is an association between {} and Preference.\".format(variable))\n",
    "    else:\n",
    "        print(\"Fail to reject the null hypothesis: No association between {} and Preference.\".format(variable))\n",
    "  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_proportions(variable='Gender',data=customer_churn_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender vs Churn\n",
    "# prepare the data for the grouped bar chart visualisation\n",
    "# convert df into DplyFrame object to then perform dplyr like operations\n",
    "\n",
    "\n",
    "fig=px.bar(\n",
    "    data_frame=calculate_proportions(variable='Gender',data=customer_churn_df),\n",
    "    x='Churn',\n",
    "    y='proportion',\n",
    "    color='Gender',\n",
    "    barmode='group',\n",
    "    text='proportion'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of Gender according to Churn\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# higher proportion of females churning as compared with males\n",
    "\n",
    "# possibly more targeted approach toward rentention of females as compared with males"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_test(customer_churn_df,'Gender')\n",
    "\n",
    "# does not seem to be an association with Gender an Churn\n",
    "# assumptions of chi square test are met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subscription Type vs Churn\n",
    "\n",
    "\n",
    "fig=px.bar(\n",
    "    data_frame=calculate_proportions(variable='Subscription Type',data=customer_churn_df),\n",
    "    x='Churn',\n",
    "    y='proportion',\n",
    "    color='Subscription Type',\n",
    "    barmode='group',\n",
    "    text='proportion'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of SubscriptionType according to Churn\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# does not seem to be much difference in proportion for churned vs not churned by subscription type\n",
    "# seems like the subscription type would not be a good predictor for churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_test(customer_churn_df,'Subscription Type')\n",
    "\n",
    "# does not seem to be an association with Subscription Type an Churn\n",
    "# assumptions of chi square test are met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contract Length vs Churn\n",
    "\n",
    "fig=px.bar(\n",
    "    data_frame=calculate_proportions(variable='Contract Length',data=customer_churn_df),\n",
    "    x='Churn',\n",
    "    y='proportion',\n",
    "    color='Contract Length',\n",
    "    barmode='group',\n",
    "    text='proportion'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of Contract Type according to Churn\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# The proportion of customers who churn are highest for monthly contracts\n",
    "\n",
    "# more intresting find is that we have no customers who are on monthly contracts that have not yet churned\n",
    "# it may be worth looking at how one can convert monthly paying customers into either quaterly or yearly paying customers\n",
    "# this could have an impact on reducing churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_test(customer_churn_df,'Contract Length')\n",
    "\n",
    "# does not seem to be an association between Contact Length and Churn\n",
    "# assumptions of chi square test are met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Cat vs Churn\n",
    "\n",
    "fig=px.bar(\n",
    "    data_frame=calculate_proportions(variable='Age Cat',data=customer_churn_df),\n",
    "    x='Churn',\n",
    "    y='proportion',\n",
    "    color='Age Cat',\n",
    "    barmode='group',\n",
    "    text='proportion'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of Age Catergories according to Churn\"\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# proportion of middle age adults was the highest churn \n",
    "# the more intresting pattern is that all senior adults churned\n",
    "\n",
    "# this could suggest the product/service is maybe to complicated for them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_test(customer_churn_df,'Age Cat')\n",
    "# I would not trust the chi sqaure test in this case since all of the senior adults have churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Cat vs Churn\n",
    "fig=px.bar(\n",
    "    data_frame=calculate_proportions(variable='Support Cat',data=customer_churn_df),\n",
    "    x='Churn',\n",
    "    y='proportion',\n",
    "    color='Support Cat',\n",
    "    barmode='group',\n",
    "    text='proportion'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Distribution of Support Catergories according to Churn\"\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df[customer_churn_df['Churn']==0]['Support Calls'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square_test(customer_churn_df,'Support Cat')\n",
    "# In this the chi square test is not to be trusted as we can clearly see a pattern for customers who churn\n",
    "# those who churn have a high proportion of customers who have high number of support calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. **Explore Possible Interactions With Response Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.factorplots import interaction_plot\n",
    "\n",
    "def interaction_plot_func(numeric_var:str,cat_var:str,data:pd.DataFrame):\n",
    "    '''\n",
    "    Function to plot an interaction plot with numeric variable passed in and with Churn and cat var\n",
    "    '''\n",
    "\n",
    "    fig = interaction_plot(\n",
    "        x=data['Churn'], \n",
    "        trace=data[cat_var], \n",
    "        response=data[numeric_var], \n",
    "        colors=[\"red\", \"blue\",\"orange\"], \n",
    "        markers=[\"D\", \"^\",\"X\"], \n",
    "        ms=8  # Marker size\n",
    "    )\n",
    "\n",
    "    plt.xlabel(\"Churn\")\n",
    "    plt.ylabel(\"Mean {}\".format(numeric_var))\n",
    "    plt.title(\"Interaction Plot: {} by Churn and {}\".format(numeric_var,cat_var))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Why have all the Senior Adults Churned?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "interaction_plot_func('Usage Frequency','Age Cat',customer_churn_df)\n",
    "\n",
    "# Mean usage frequency for seniors for those who churned was the highest - does not indicate why seniors churned\n",
    "\n",
    "# looks like we do have an interaction between usage frequency, age cat and churn based on the plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at investigating the interaction further\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.box(customer_churn_df, x=\"Age Cat\", y=\"Usage Frequency\", color=\"Churn\")\n",
    "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
    "fig.update_layout(\n",
    "    title=\"Grouped box plot comparing Usage Frequency by Age Cat & Churn\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Looks like we have a difference in the median usage frequency for middle aged customers for those who churn and do not churn\n",
    "# for those who do not churn the median usage frequency is higher\n",
    "\n",
    "# possibly the same case in the young adult category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "interaction_plot_func('Payment Delay','Age Cat',customer_churn_df)\n",
    "# does not look like we have an interaction\n",
    "# Mean payment delay for all those who churned was lowest for seniors but not by that much\n",
    "# Payment delay does not indicate why all seniors churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_plot_func('Tenure','Age Cat',customer_churn_df)\n",
    "\n",
    "# Could have slight interaction based on the plot below\n",
    "# Mean tenure for all those who churned was lowest for seniors , but not by that much\n",
    "# Do not think tenure explains why seniors all churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the possible interaction abit more\n",
    "fig = px.box(customer_churn_df, x=\"Age Cat\", y=\"Tenure\", color=\"Churn\")\n",
    "fig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\n",
    "fig.update_layout(\n",
    "    title=\"Grouped box plot comparing Tenure by Age Cat & Churn\"\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# The median tenure for both young and middle aged adults seems to be lower for those who churned and higher for those \n",
    "# who did not churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_plot_func('Total Spend','Age Cat',customer_churn_df)\n",
    "\n",
    "# Does not seem like we have any possible interaction\n",
    "# Mean total spend for all seniors who churned is not much diffrent from the other groups\n",
    "# Total spend does not seem to explain why all seniors churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement multivariate analysis for categorical variables to better understand more complex relationships in the data\n",
    "import prince\n",
    "df=customer_churn_df[['Age Cat','Support Cat','Churn']]\n",
    "# instantiate MCA class\n",
    "mca = prince.MCA(n_components = 2)\n",
    "# get principal components\n",
    "mca = mca.fit(df)\n",
    "mca.plot_coordinates(df,show_column_labels=True,show_row_points=False,show_row_labels=False)\n",
    "\n",
    "# I have checked the other relationships with the other cat vars in the data\n",
    "# from my observations only the support cat var showed the most significant association with Age Cat and churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From the MCA plot above it seems like Senior adults churning is associated with high support\n",
    "- Given that the variations explained in the data by the 2 componets is around 57% , we will proceed to do further verification of this below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to verify this \n",
    "df=customer_churn_df[['Churn','Support Cat','Age Cat']]\n",
    "grouped_data=df[df['Churn']==1].groupby(['Support Cat','Age Cat']).count()\n",
    "grouped_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the analysis above\n",
    "# we can see that we have the highest number of seniors who churned in the high support category\n",
    "# This indicates to us that they probably had some technical difficulty with usage of the product/service\n",
    "# 45.6 % of seniors who churned had high number of support calls\n",
    "# 27.2 % of seniors who churned had medium number of support calls\n",
    "# 27.1 % of seniors who churned had low number of support calls\n",
    "# perhaps simpler user experiences can aid in reducing churn for the senior age category\n",
    "# This may also be a possible interaction effect to include in the model (Support Cat and Age Cat Interaction Effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclutions: Why have all seniors churned?**\n",
    " - The data suggests the following\n",
    " - High number of support calls seems to be associated with increased churn in the Senior age category\n",
    " - 45.6 % of seniors who churned had high number of support calls\n",
    " - 27.2 % of seniors who churned had medium number of support calls\n",
    " - 27.1 % of seniors who churned had low number of support calls\n",
    " - Better understanding the nature of the support calls can guide improving the product/service user experience to being simpler\n",
    " - Ease of use could result in reduced churn within the senior age category resulting in higher revenue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question: Why have all customers with a monthly subscription churned?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Interaction plot\n",
    "interaction_plot_func('Total Spend','Contract Length',customer_churn_df)\n",
    "\n",
    "# from the interaction plot we do not see any interaction between contract length and total spend\n",
    "# total spend for monthly users who have churned was the highest\n",
    "# total spend does not indicate why all monthly subscriptions have churned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_plot_func('Payment Delay','Contract Length',customer_churn_df)\n",
    "\n",
    "# does not seem to be any interaction between payment delay and contract length\n",
    "# mean monthly payment delay is lowest for monthly subscriptions but does not seem all that low relative to the other subscription types\n",
    "# payment delay does not explain why all monthly subscriptions have churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_plot_func('Usage Frequency','Contract Length',customer_churn_df)\n",
    "\n",
    "# does not seem to be any interaction between Usage Frequency and Contract Length\n",
    "\n",
    "# mean usage frequency for all monthly subcriptions is higher than other subcription types but not by much\n",
    "# usage frequency does not explain why all monthly subcriptions have churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_plot_func('Support Calls','Contract Length',customer_churn_df)\n",
    "\n",
    "# Does not seem like we have an interaction between support calls and contract length\n",
    "# mean total spend is lowest for monthly subcriptions who churned but not by that much relative to other subcriptions\n",
    "# total spend does not explain why all monthly subcriptions churned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_churn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement multivariate analysis for categorical variables to better understand more complex relationships in the data\n",
    "import prince\n",
    "df=customer_churn_df[['Contract Length',\"Support Cat\",'Churn']]\n",
    "# instantiate MCA class\n",
    "mca = prince.MCA(n_components = 2)\n",
    "# get principal components\n",
    "mca = mca.fit(df)\n",
    "mca.plot_coordinates(df,show_column_labels=True,show_row_points=False,show_row_labels=False)\n",
    "\n",
    "# I have checked the other relationships with the other cat vars in the data\n",
    "# from my observations only the support cat var showed the most significant association with contract length and churn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the age cat , contract length and how many churned \n",
    "df=customer_churn_df[['Support Cat','Contract Length','Churn']]\n",
    "df[df['Churn']==1].groupby(['Support Cat','Contract Length']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looks like we have the following relationship for explaining partially why all monthly subscriptions churned\n",
    "# High levels of support seemed to be associated with monthly subscriptions churning\n",
    "\n",
    "# From the analysis above 45.29 % of monthly subscriptions who churned had high number of support calls\n",
    "# this is quite a significant figure\n",
    "\n",
    "# 27.5 % of monthly subscriptions churned had low support calls\n",
    "\n",
    "# 27.1 % of montly subscriptions churned had medium support calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclutions: Why have all monthly subcriptions churned?**\n",
    " - From the data we can observe the following\n",
    " - A high number of support calls seems to be associated with monthly subsciptions churning\n",
    " - 45.29 % of monthly subscriptions who churned had high number of support calls\n",
    " - 27.5 % of monthly subscriptions churned had low support calls\n",
    " - 27.1 % of montly subscriptions churned had medium support calls\n",
    " - Understanding the nature of the support calls will have an impact in reducing churn in monthly subscriptions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify possible multicollinearity**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix + heatmap\n",
    "df=customer_churn_df.drop(columns=['CustomerID','age_scaled','age_group','support_calls_scaled','support_calls_group',\n",
    "'support_calls_cluster','cluster'\n",
    "])\n",
    "numeric_columns=df.select_dtypes(include=['float64'])\n",
    "correlation_matrix=numeric_columns.corr()\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=correlation_matrix.values,\n",
    "    x=correlation_matrix.columns,\n",
    "    y=correlation_matrix.columns,\n",
    "    colorscale='RdBu_r',  # Adjust color scale\n",
    "    colorbar=dict(title=\"Correlation\"),\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Correlation Heatmap\",\n",
    "    xaxis=dict(title='Variables', tickangle=45),\n",
    "    yaxis=dict(title='Variables'),\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "# The total usage var that was created is highly correlated with usage frequency and tenure\n",
    "# makes sense since the variable was created from these vars\n",
    "# we will have to either not include total usage or include it and remove tenure and usage frequency\n",
    "# we can build 2 seperate models and see if any model is better than the other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write prepared data to Modelling folder\n",
    "import os\n",
    "\n",
    "folder_path='../Modelling'\n",
    "file_path = os.path.join(folder_path, 'prepared_data.csv')\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
